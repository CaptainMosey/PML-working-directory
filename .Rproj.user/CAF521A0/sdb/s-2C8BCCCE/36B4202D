{
    "contents" : "---\ntitle: \"Practical Machine Learning\"\nauthor: \"Erik\"\ndate: \"06/14/2015\"\noutput: html_document\n---\n\nExecutive summary\n--------------------\n\nThe Weight Lifting Exercises (WLE) dataset was produced by having 6 participants performing dumbbel curls properly amd improperly while activities were recorded by 4 \"on-body\" sensors (footnote 1). Using a random forest method, I was able to produce an algorithm which can correctly assign activity quality with an out of sample error rate of XXXXX, as confirmed by cross-validation. this algorithm was then used to correctly classify unknown activity quality in the \"pml=-testing.csv\" data set.\n\n\n\n\n\n\nSet Seed Load Data\n------------------------------\n\nIn preparation for analysis, the random number seed was set to allow reproducibility and the data were loaded from csv files downloaded from the course website. R packages ISLR,caret,Hmisc,RANN,ggplot2, and rattle were loaded into R studio.\n\n\n\n```{r, echo=FALSE, cache=TRUE}\n#take these out\nlibrary(ISLR)\nlibrary(caret)\nlibrary(Hmisc)\nlibrary(RANN)\nlibrary(ggplot2)\nlibrary(rattle)\n```\n```{r, echo=TRUE, cache=TRUE}\nset.seed(365)\n\npml.training<-read.csv(\"pml-training.csv\")\npml.testing<-read.csv(\"pml-testing.csv\")\n```\n\nBuilding the model \n------------------\n\nData Slicing\n============\n\nThe training set data were then sliced into train and test segments (60/40) to allow for cross-validation of the method on an untouched test set.\n\n\n```{r, echo=TRUE, cache=TRUE}\ninTrain<-createDataPartition(y=pml.training$classe,p=0.6,list=FALSE)\n\ntrain<-pml.training[inTrain,]\ntest<-pml.training[-inTrain,]\n```\n\nPre-processing\n===============\n\nThis train set was then processing to remove columns which were constant (not useful in the model), and missing data was imputed using the knnImpute method. Imputing was performed for all sensor data columns in the data set (columns 8, through the next-to-last column which was the \"classe\" exercise quality factor).\n\n```{r, echo=TRUE, cache=TRUE}\nremoveColumns=nearZeroVar(x=train,freqCut=95/5)\n\ntrain<-train[,-removeColumns]\n#changed to -1 from -2, 6/14/15 6:04p\nimputeObj=preProcess(train[,8:ncol(train)-2],method=\"knnImpute\")\ntrain[,8:ncol(train)-2]<-predict(imputeObj,train[,8:ncol(train)-2])\n```\n\nFitting a Linear Regression Model\n================================\n\nThe data was processed further to fit a linear model. An additional column was created to change the exercise quality factor (A,B,C,D,E) to a numeric value (1,2,3,4,5). Alinear model was fit (lm1). Using this model on the cross-validation data showed poor results (out of sample error - XXXXXXXXXX)\n\n\n```{r, echo=TRUE, cache=TRUE}\nfor(i in 1:nrow(train)){\n  train$classn[i]<-utf8ToInt(as.character(train$classe[i]))-64\n}\n\n\n#M<-abs(cor(train))\n#diag(M)<-0\n#which(M>0.8, arr.ind=T)\n#subset train\nx<-colnames(train[,c(8:ncol(train)-2,ncol(train))])\ntrain2<-train[,c(8:ncol(train)-2,ncol(train))]\ncolnames(train2)<-x\n#predict w regression\n\nlm1<-lm(classn~.,data=train2)\npred<-predict(lm1,train2)\nqplot(classn,pred,data=train2)\n#pml.training$class<-dummyVars(pml.training)\n\nlmTrain<-predict(lm1,train2)\ntrain2$predRight<-lmTrain==train2$classe\n#print(table(lmTrain,train2$classe))\n\n\n\n```\n\nRandom Forest Model\n==================\n\nThe data were then reprocessed to remove the \"classn\" column, and a random forest method was used to generate an algorithm. When tested on the cross-validation sample, an estimated out of sample error of XXXX was seen. \n\n\n```{r, echo=TRUE, cache=TRUE}\n\n#try trees\nx<-colnames(train[,c(8:ncol(train)-1)])\ntrain2<-train[,c(8:ncol(train)-1)]\ncolnames(train2)<-x\n\n\n\n\n#modFit<-train(classe~.,method=\"rpart2\",data=train2,maxdepth=10)\nmodFit<-train(classe~.,method=\"rf\",data=train2,prox=TRUE)\nprint(modFit)\n#getTree(modFit$finalModel,k=2)\n\n\n#print(predict(modFit,newdata=train2))\nplot(train$classe,(predict(modFit,newdata=train2)))\n#print(predict(modFit,newdata=trainL))\n\n\npredTrain=predict(modFit,train2)\ntrain2$predRight<-predTrain==train2$classe\nprint(table(predTrain,train2$classe))\n\n\n```\nCross Validation\n=============================\n\n\nThe cross-validation data set was processed idenitcally to the training set and run through the random forest algorithm. \n\n```{r, echo=TRUE, cache=TRUE}\n#remove same columns as from training sets\ntest<-test[,-removeColumns]\n\n#Impute same- changed to -1 from -2 6:24pm 6/14/15\n#test data has \"problem ID column instead of classe\"\ntest[,8:ncol(test)-1]<-predict(imputeObj,test[,8:ncol(test)-1])\n\n\n\npredTest=predict(modFit,test)\ntest$predRight<-predTest==test$classe\nprint(table(predTest,test$classe))\n\n#out of sample error\n\nOSE<-1-(sum(test$predRight/nrow(test)))\nprint(paste(\"The out of sample error is \",toString(OSE),\", with \",toString(sum(test$predRight)),\"correct predicitions out of \",toString(nrow(test),\" samples.\")))\n\n```\nAssign Excercise Quality on Testing Data\n===================================\n\nFinally, process the testing data and assign excercise quality for the 20 unknowns:\n\n\n\n```{r, echo=TRUE, cache=TRUE}\n\n#remove same columns as from training sets\npml.testing<-pml.testing[,-removeColumns]\nsummary(pml.testing)\n#Impute same- changed to -1 from -2 6:24pm 6/14/15\n#test data has \"problem ID column instead of classe\"\npml.testing[,8:ncol(pml.testing)-2]<-predict(imputeObj,pml.testing[,8:ncol(pml.testing)-2])\n\n\npredTesting=predict(modFit,pml.testing)\npml.testing$pred<-predTesting\nans<-pml.testing$problem_id\nans<-cbind(ans,as.character(pml.testing$pred))\n\nprint(ans)\n\n\n\n```\n\n",
    "created" : 1434272611626.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "2225441093",
    "id" : "36B4202D",
    "lastKnownWriteTime" : 1434340237,
    "path" : "~/MOOC/Coursera - predictive machine learning/Practical Machine Learning project/pml.Rmd",
    "project_path" : "pml.Rmd",
    "properties" : {
        "tempName" : "Untitled1"
    },
    "source_on_save" : false,
    "type" : "r_markdown"
}